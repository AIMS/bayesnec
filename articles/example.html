<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>General usage • bayesnec</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/yeti/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="General usage">
<meta property="og:description" content="bayesnec">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">bayesnec</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/example.html">General usage</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/aims/bayesnec/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="example_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>General usage</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/aims/bayesnec/blob/master/vignettes/example.Rmd"><code>vignettes/example.Rmd</code></a></small>
      <div class="hidden name"><code>example.Rmd</code></div>

    </div>

    
    
<div id="bayesnec" class="section level1">
<h1 class="hasAnchor">
<a href="#bayesnec" class="anchor"></a><em>bayesnec</em>
</h1>
<p>The <em>bayesnec</em> is an R package to fit concentration(dose) - response curves to toxicity data, and derive No-Effect-Concentration (<em>NEC</em>), No-Significant-Effect-Concentration (<em>NSEC</em>), and Effect-Concentration (of specified percentage ‘x’, <em>ECx</em>) thresholds from non-linear models fitted using Bayesian MCMC fitting methods via <em>brms</em> <span class="citation">(Bürkner 2017, 2018)</span> and <em>stan</em>. The package is an adaptation and extension of an initial package <em>jagsNEC</em> <span class="citation">(Fisher, Ricardo, and Fox 2020)</span> which as based on the <em>R2jags</em> package <span class="citation">(Su and Yajima 2015)</span> and <em>jags</em> <span class="citation">(<span class="citeproc-not-found" data-reference-id="Plummer2003"><strong>???</strong></span>)</span>.</p>
</div>
<div id="background" class="section level1">
<h1 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h1>
<p>Bayesian model fitting can be difficult to automate across a broad range of usage cases, particularly with respect to specifying valid initial values and appropriate priors. This is one reason the use of Bayesian statistics for <em>NEC</em> estimation (or even <em>ECx</em> estimation) is not currently widely adopted across the broader ecotoxicological community, who rarely have access to specialist statistical expertise. The <em>bayesnec</em> package provides an accessible interface specifically for fitting <em>NEC</em> models and other concentration-response models using Bayesian methods. A range of models are specified based on the known distribution of the “concentration” or “dose” variable (the predictor, x) as well as the “response” (y) variable. The model formula, including priors and the <em>init</em> function required to call a <em>brms</em> model are automatically generated based on information contained in the supplied data. While the distribution of the x and y variables can be specified directly, <em>bayesnec</em> will automatically ‘guess’ the correct distribution to use based on the characteristics of the provided data.</p>
<p>This project started with an implementation of the <em>NEC</em> model based on that described in <span class="citation">(Fox 2010)</span> using R2jags. The package has been further generalised to allow a large range of response variables to be modelled using the appropriate statistical distribution. While the original <em>jagsNEC</em> implementation supported gaussian, poisson, binomial, gamma, negbin and beta response data <em>bayesnec</em> supports any of the <em>brms</em> families. We have since also further added a range of alternative <em>NEC</em> model types, as well as a range of typically used concentration-response models (such as 4-parameter logistic and weibull models) that have no <em>NEC</em> ‘step’ function but simply model the response as a smooth function of concentration, as can be fit using other commonly used frequentist packages such as drc <span class="citation">(Ritz et al. 2016)</span>.</p>
<p>Specific models can be fit directly using <em>bnec</em>. Alternatively it is possible to fit a a custom model set, specific model set or all of the available models. When multiple models are specified the <em>bnec</em> function returns a model weighted estimate of predicted posterior values, based on watanabe information criteria (WAIC) model weights, analogous to the way model weights are generated using AIC or AICc <span class="citation">(Burnham and Anderson 2002)</span>. It is also possible to obtain all individual model fits from the fitted <em>bayesnecfit</em> model object if required. Multi-model inference can be useful where there are a range of plausible models that could be used <span class="citation">(Burnham and Anderson 2002)</span> and has been recently adopted in ecotoxicology for SSD model inference <span class="citation">(Thorley and Schwarz 2018)</span>.</p>
<p>An additional endpoint has also been derived using Bayesian posterior predicted values to estimate the “No-Statistical-Effect-Concentration” as the concentration at which predicted values for each MCMC chain fall below a lower percentile bound (defined as <em>sig.val</em>) of the control, which is assumed to be the lowest treatment (x_var) concentration in the data. <em>NSEC</em> estimates are currently used to approximate <em>NEC</em> for models without a specific <em>NEC</em> step parameter (in <em>bayesnec</em> these have the prefix <em>ecx</em> in their model name).</p>
<p>Important information on the current package is contained in the <em>bayesnec</em> helpfiles (see <em>?bayesnec</em> or <em>?bnec</em>).</p>
<p>This package is currently under development. We are keen on any feedback regarding usage, and especially bug reporting that includes an easy to run self contained reproducible example of unexpected behaviour or example model fits that fail to converge (have poor chain mixing) or yield other errors. Such information will hopefully help us towards building a more robust package. We cannot help troublshoot issues if an easy to run reproducible example is not supplied.</p>
</div>
<div id="installation" class="section level1">
<h1 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h1>
<p>To install the latest version from github (<a href="https://github.com/AIMS/bayesnec" class="uri">https://github.com/AIMS/bayesnec</a>) use:</p>
<div class="sourceCode" id="cb1"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span>(<span class="st">"remotes"</span>)
<span class="kw">remotes</span>::<span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html">install_github</a></span>(<span class="st">"AIMS/bayesnec"</span>)
</pre></div>
</div>
<div id="examples" class="section level1">
<h1 class="hasAnchor">
<a href="#examples" class="anchor"></a>Examples</h1>
<div id="fitting-the-nec3param-model-using-bnec" class="section level2">
<h2 class="hasAnchor">
<a href="#fitting-the-nec3param-model-using-bnec" class="anchor"></a>Fitting the nec3param model using <em>bnec</em>
</h2>
<p>Here we include some examples showing how to use the package to fit an <em>NEC</em> model to binomial, proportional, count and continuous response (y) data. The examples are those used by Gerard Ricardo at: <a href="https://github.com/gerard-ricardo/NECs/blob/master/NECs" class="uri">https://github.com/gerard-ricardo/NECs/blob/master/NECs</a>. Here we show how to run the same <em>jags</em> models using the <em>bayesnec</em> package.</p>
<div id="binomial-data" class="section level3">
<h3 class="hasAnchor">
<a href="#binomial-data" class="anchor"></a>Binomial data</h3>
<p>Where data are a count out of a total (such as the percentage survival of individuals, for example) y is binomial. First we read in the binomial example from pastebin, and then plot the “concentration” or x data, in this case raw.x.</p>
<div class="sourceCode" id="cb2"><pre class="downlit">
<span class="kw">binom.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span>(<span class="st">"https://pastebin.com/raw/zfrUha88"</span>, header = <span class="fl">TRUE</span>, dec = <span class="st">","</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(<span class="kw">binom.data</span>)
<span class="co">#&gt; 'data.frame':    48 obs. of  3 variables:</span>
<span class="co">#&gt;  $ raw.x: chr  "0.1" "0.1" "0.1" "0.1" ...</span>
<span class="co">#&gt;  $ suc  : int  101 106 102 112 58 158 95 91 93 113 ...</span>
<span class="co">#&gt;  $ tot  : int  175 112 103 114 69 165 109 92 99 138 ...</span>
<span class="kw">binom.data</span><span class="op">$</span><span class="kw">raw.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span>(<span class="kw">binom.data</span><span class="op">$</span><span class="kw">raw.x</span>))
<span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span>(<span class="kw">binom.data</span><span class="op">$</span><span class="kw">raw.x</span>)
<span class="co">#&gt; [1]   0.1 400.0</span>
</pre></div>
<p>In this case for x, lowest concentration is 0.1 and the highest is 400. The data are right skewed and on the continuous scale. This type of distribution for the x data are common for concentration response experiments, where the x “concentration” data are the concentration of contaminants, or dilutions. The current default in <em>bayesnec</em> is to estimate the appropriate distribution(s) and priors for both the <em>y_type</em> and <em>x_type</em> arguments, but it is possible to supply these arguments directly.</p>
<p>The data are clearly binomial, with the header “suc” - indicating the number of ‘successes’ in the binomial call, with ‘tot’ clearly indicating the number of trials.</p>
<p>The main ‘working’ function in <em>bayesnec</em> is the function <em>bnec</em>, which calls the other necessary functions and fits the <em>brms</em> model. See ?<em>bnec</em> for more details. We run <em>bnec</em> by supplying <em>data</em> - a data.frame containing the data for the model fitting, here, binom.data; <em>x_var</em> - the name of the column in <em>data</em> which contains the concentration data or ‘x’ data to be used in the <em>NEC</em> model fit, and <em>y_var</em> - the name of the column in <em>data</em> which contains the response or ‘y’ data to be used in the <em>NEC</em> model fit. In our example here, as this is binomial, we must also supply <em>trials_var</em>, which is the name of the column in <em>data</em> which contains the number of trials in the binomial call.</p>
<p><em>bnec</em> will guess the data types for use, although we could manually specify <em>y_type</em> as “binomial” and <em>x_type</em> as “gamma”. This example fits without specifying either, but <em>trials_var</em> must be supplied.</p>
<pre><code>#&gt; Loading required package: brms
#&gt; Loading required package: Rcpp
#&gt; Loading 'brms' package (version 2.13.5). Useful instructions
#&gt; can be found by typing help('brms'). A more detailed introduction
#&gt; to the package is available through vignette('brms_overview').
#&gt; 
#&gt; Attaching package: 'brms'
#&gt; The following object is masked from 'package:stats':
#&gt; 
#&gt;     ar
#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_nec ~ gamma(2, 0.0533333333333333)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL 'b219b9b3bc2387c567eef001e65b92c9' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000227 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.27 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 11.0666 seconds (Warm-up)
#&gt; Chain 1:                1.94648 seconds (Sampling)
#&gt; Chain 1:                13.0131 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b219b9b3bc2387c567eef001e65b92c9' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 9.2e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.92 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 11.7847 seconds (Warm-up)
#&gt; Chain 2:                1.74318 seconds (Sampling)
#&gt; Chain 2:                13.5279 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b219b9b3bc2387c567eef001e65b92c9' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 3.7e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 12.0502 seconds (Warm-up)
#&gt; Chain 3:                1.43236 seconds (Sampling)
#&gt; Chain 3:                13.4825 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b219b9b3bc2387c567eef001e65b92c9' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 9.1e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.91 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 10.6687 seconds (Warm-up)
#&gt; Chain 4:                0.866563 seconds (Sampling)
#&gt; Chain 4:                11.5352 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: Found 3 observations with a pareto_k &gt; 0.7 in model 'fit'. It is
#&gt; recommended to set 'moment_match = TRUE' in order to perform moment matching for
#&gt; problematic observations.
#&gt; Warning: 
#&gt; 23 (47.9%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec3param model using a binomial distribution.</code></pre>
<p>The function shows the progress of the <em>brms</em> fit and returns the usual <em>brms</em> output (with a few other elements added to this list). The function <em>plot(out$fit)</em> can be used to plot the chains and the chain ACF, so we can assess mixing and look for other potential issues with the model fit. Initially <em>bayesnec</em> will attempt to use starting values generated by the <em>init</em> function that we have specified for that type of model fit. It will run a small number of iterations and then test for good mixing. If the model fails to fit or the mixing is not very good (among chain variance is a lot bigger than within chain variance) <em>bayesnec</em> with try up to <em>n.tries</em> more times to fit the data using the generated <em>init</em> function to try and obtain a successfuly fitted model with good mixing. If this still fails to yield a successful and/or well mixed model, <em>bayesnec</em> will try up to <em>n.tries</em> more times using the default initial values as generated by R2jags. If no model is successfully fit an error will be returned indicating the model could not be fit succesfully. If a model is fit but still has poor mixing even after <em>n.tries</em> attempts, the model with the best mixing will be returned, with a warning to cautiously interpret the results and inspect the chain mixing diagnostic plot.</p>
<div class="sourceCode" id="cb4"><pre class="downlit">
<span class="co">#plot(out$fit)</span>
</pre></div>
<p>In our example, the chains are well mixed and our ACF plot looks good, so we can go ahead and interpret this model. There are a range of brms warnings messages, for now as long as the chain plots are good and the parameter estimates are reasonable it is generally ok to interpret a model.</p>
<p>The function <em>plot</em> can be used to plot the fitted model. You can also make your own plot from the data included in the returned <em>bayesnecfit</em> object from the call to <em>bnec</em>. In this example, this could be extracted using <em>out$pred.vals</em>. Here we use the default plot method from <em>bayesnec</em>.</p>
<div class="sourceCode" id="cb5"><pre class="downlit">
<span class="co">#par(mfrow = c(1, 1))</span>
<span class="co">#plot(out)</span>
</pre></div>
<p>Alternatively, we can use the built in <em>brms</em> methods to plot the <em>brms</em> fit directly. For example:</p>
<div class="sourceCode" id="cb6"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="kw"><a href="http://ggplot2.tidyverse.org">ggplot2</a></span>)
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="kw"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span>)
<span class="co">#&gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</span>
<span class="co">#&gt; ✔ tibble  3.0.3     ✔ dplyr   1.0.2</span>
<span class="co">#&gt; ✔ tidyr   1.1.2     ✔ stringr 1.4.0</span>
<span class="co">#&gt; ✔ readr   1.3.1     ✔ forcats 0.5.0</span>
<span class="co">#&gt; ✔ purrr   0.3.4</span>
<span class="co">#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──</span>
<span class="co">#&gt; ✖ dplyr::filter() masks stats::filter()</span>
<span class="co">#&gt; ✖ dplyr::lag()    masks stats::lag()</span>
<span class="kw">df</span><span class="op">&lt;-</span><span class="kw">out</span><span class="op">$</span><span class="kw">fit</span><span class="op">$</span><span class="kw">data</span> <span class="op">%&gt;%</span> <span class="fu">mutate</span>(prop=<span class="kw">y</span><span class="op">/</span><span class="kw">trials</span>)
<span class="co">#plot(brms::conditional_effects(out$fit))[[1]] +</span>
<span class="co">#     geom_point(data= df, aes(x=x, y = prop), inherit.aes = FALSE) </span>
</pre></div>
<p>This model fit doesn’t look great. You can see that the error bounds around the fit are far too narrow for this data, suggesting over dispersion of this model (meaning that the data are more variable than this model fit predicts). We discuss this more below.</p>
</div>
<div id="beta-data" class="section level3">
<h3 class="hasAnchor">
<a href="#beta-data" class="anchor"></a>Beta data</h3>
<p>Sometimes the response variable is distributed between <em>0</em> and <em>1</em> but is not a straight forward binomial. A common example in coral ecology is maximum quantum yield (the proportion of light used for photosynthesis when all reaction centres are open) which is a measure of photosynthetic efficiency calculated from PAM data. Here we have a proportion value that is not based on trials and successes. In this case there are no theoretical ‘trials’ and the data must be modelled using a beta distribution.</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_nec ~ gamma(2, 1.05702947974578)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '6903135230a6b818174962a7b50f698a' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000426 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 4.26 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 32.8944 seconds (Warm-up)
#&gt; Chain 1:                11.8743 seconds (Sampling)
#&gt; Chain 1:                44.7686 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '6903135230a6b818174962a7b50f698a' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 0.000243 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 2.43 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 30.307 seconds (Warm-up)
#&gt; Chain 2:                11.1109 seconds (Sampling)
#&gt; Chain 2:                41.4178 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '6903135230a6b818174962a7b50f698a' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 0.000223 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 2.23 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 23.9056 seconds (Warm-up)
#&gt; Chain 3:                7.87924 seconds (Sampling)
#&gt; Chain 3:                31.7849 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '6903135230a6b818174962a7b50f698a' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 7.7e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.77 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 22.726 seconds (Warm-up)
#&gt; Chain 4:                7.29533 seconds (Sampling)
#&gt; Chain 4:                30.0213 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: 
#&gt; 2 (1.2%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec3param model using a beta distribution.</code></pre>
<div class="sourceCode" id="cb8"><pre class="downlit">
<span class="co">#plot(out$fit)</span>
</pre></div>
<div class="sourceCode" id="cb9"><pre class="downlit">
<span class="co">#par(mfrow = c(1, 1))</span>
<span class="co">#plot(out)</span>
</pre></div>
</div>
<div id="poisson-data" class="section level3">
<h3 class="hasAnchor">
<a href="#poisson-data" class="anchor"></a>Poisson data</h3>
<p>Where data are a count (of, for example, individuals or cells) y is poisson. Such data are distributed from <em>0</em> to <em>Inf</em> and are integers. First we read in the count data example from pastebin, and then plot the “concentration” or x data, Again, this is raw.x, and distributed as in our binomial example above.</p>
<div class="sourceCode" id="cb10"><pre class="downlit">
<span class="kw">count.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span>(<span class="st">"https://pastebin.com/raw/ENgNSgf7"</span>, header = <span class="fl">TRUE</span>, dec = <span class="st">","</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(<span class="kw">count.data</span>)
<span class="co">#&gt; 'data.frame':    48 obs. of  2 variables:</span>
<span class="co">#&gt;  $ raw.x: chr  "0.1" "0.1" "0.1" "0.1" ...</span>
<span class="co">#&gt;  $ count: int  164 100 103 102 102 101 131 102 112 100 ...</span>

<span class="kw">count.data</span><span class="op">$</span><span class="kw">raw.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span>(<span class="kw">count.data</span><span class="op">$</span><span class="kw">raw.x</span>))

<span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span>(<span class="kw">count.data</span><span class="op">$</span><span class="kw">raw.x</span>)
<span class="co">#&gt; [1]   0.1 190.0</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span>(mfrow = <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">2</span>, <span class="fl">1</span>))
<span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span>(<span class="kw">count.data</span><span class="op">$</span><span class="kw">raw.x</span>)
<span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span>(<span class="kw">count.data</span><span class="op">$</span><span class="kw">count</span>)
</pre></div>
<p><img src="man/ignore/example-get-poisson-data-1.png" width="700"></p>
<p>First we supply <em>bnec</em> with <em>data</em> (count.data), and specify <em>x_var</em> and <em>y_var</em>. As we have concentration data, our <em>x_type</em> would be the gamma distribution, and <em>y_type</em> is “poisson”. The default behaviour to guess the variable types works for this example.</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ gamma(2, 0.0192307692307692)
#&gt; b_nec ~ gamma(2, 0.0809716599190283)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '7b7ca65d04c0d0109b32f593e92cb5df' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000149 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.49 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 3.76448 seconds (Warm-up)
#&gt; Chain 1:                0.836371 seconds (Sampling)
#&gt; Chain 1:                4.60085 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '7b7ca65d04c0d0109b32f593e92cb5df' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 6.7e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.67 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 5.64833 seconds (Warm-up)
#&gt; Chain 2:                1.38249 seconds (Sampling)
#&gt; Chain 2:                7.03083 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '7b7ca65d04c0d0109b32f593e92cb5df' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 6.7e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.67 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 5.11584 seconds (Warm-up)
#&gt; Chain 3:                0.959227 seconds (Sampling)
#&gt; Chain 3:                6.07507 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '7b7ca65d04c0d0109b32f593e92cb5df' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 2.7e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 4.56398 seconds (Warm-up)
#&gt; Chain 4:                0.470185 seconds (Sampling)
#&gt; Chain 4:                5.03416 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
#&gt; Running the chains for more iterations may help. See
#&gt; http://mc-stan.org/misc/warnings.html#bulk-ess
#&gt; Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
#&gt; Running the chains for more iterations may help. See
#&gt; http://mc-stan.org/misc/warnings.html#tail-ess
#&gt; Warning: Found 3 observations with a pareto_k &gt; 0.7 in model 'fit'. It is
#&gt; recommended to set 'moment_match = TRUE' in order to perform moment matching for
#&gt; problematic observations.
#&gt; Warning: 
#&gt; 6 (12.5%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec3param model using a poisson distribution.</code></pre>
<p>We first plot the model chains and parameter estimates to check the fit.</p>
<div class="sourceCode" id="cb12"><pre class="downlit">
<span class="co">#plot(out$fit)</span>
</pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit">
<span class="co">#par(mfrow = c(1, 1))</span>
<span class="co">#plot(out)</span>
</pre></div>
</div>
<div id="measure-data" class="section level3">
<h3 class="hasAnchor">
<a href="#measure-data" class="anchor"></a>Measure data</h3>
<p>Where data are a measured variable (ie length or size) y is gamma. Such data are distributed from <em>0+</em> to <em>Inf</em> and are continuous. First we read in the count data example from pastebin, and then plot the “concentration” or x data, Again, this is raw.x, and distributed as in our binomial example above.</p>
<div class="sourceCode" id="cb14"><pre class="downlit">
<span class="kw">measure.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span>(<span class="st">"https://pastebin.com/raw/pWeS6x0n"</span>, header = <span class="fl">TRUE</span>, dec = <span class="st">","</span>)
<span class="kw">measure.data</span><span class="op">$</span><span class="kw">raw.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span>(<span class="kw">measure.data</span><span class="op">$</span><span class="kw">raw.x</span>))
<span class="kw">measure.data</span><span class="op">$</span><span class="kw">measure</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span>(<span class="kw">measure.data</span><span class="op">$</span><span class="kw">measure</span>))
</pre></div>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ gamma(2, 0.0190784599231837)
#&gt; b_nec ~ gamma(2, 0.0809716599190283)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '40348b7736a50da6007b8cf0b24d35a4' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.00017 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.7 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 10.6221 seconds (Warm-up)
#&gt; Chain 1:                1.89028 seconds (Sampling)
#&gt; Chain 1:                12.5123 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '40348b7736a50da6007b8cf0b24d35a4' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 2.9e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 11.0748 seconds (Warm-up)
#&gt; Chain 2:                3.31293 seconds (Sampling)
#&gt; Chain 2:                14.3877 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '40348b7736a50da6007b8cf0b24d35a4' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 7.7e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.77 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 12.616 seconds (Warm-up)
#&gt; Chain 3:                1.63853 seconds (Sampling)
#&gt; Chain 3:                14.2546 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '40348b7736a50da6007b8cf0b24d35a4' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 7.4e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 11.0673 seconds (Warm-up)
#&gt; Chain 4:                1.46544 seconds (Sampling)
#&gt; Chain 4:                12.5327 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: 
#&gt; 5 (10.4%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec3param model using a Gamma distribution.</code></pre>
<div class="sourceCode" id="cb16"><pre class="downlit">
<span class="co">#plot(out$fit)</span>
</pre></div>
<p>The function <em>plot</em> can be used to plot the fitted model. The estimated <em>NEC</em> value can be obtained directly from the fitted model object, using <em>out$NEC</em>. EC<em>x</em> estimates can also be obtained from the <em>NEC</em> model fit, using the function <em>ecx</em>. Note these may differ from a typical 4-parameter non-linear model, as the <em>NEC</em> model is a broken stick non-linear regression and will often fall more sharply than a smooth 4-parameter non-linear curve.</p>
<div class="sourceCode" id="cb17"><pre class="downlit">
<span class="co">#par(mfrow = c(1, 1))</span>
<span class="co">#plot(out)</span>
<span class="fu"><a href="../reference/ecx.html">ecx</a></span>(<span class="kw">out</span>)
<span class="co">#&gt;   ec_10_Q50  ec_10_Q2.5 ec_10_Q97.5 </span>
<span class="co">#&gt;    63.20991    52.18468    71.76396</span>
</pre></div>
</div>
</div>
<div id="model-validation-and-selection" class="section level2">
<h2 class="hasAnchor">
<a href="#model-validation-and-selection" class="anchor"></a>Model validation and selection</h2>
<p>To explore some model validation, let us revisit our original binomial model. While chain mixing for this model is ok, the residual plot does not look fantastic. Even with good convergence, some model fits may be poor. This can result in over (the data has greater residual variance than that generated by the fitted model) and under- dispersion (the data have less residual variance than that generated by the fitted model). Generally overdispersion is more common, particularly for binomial and poisson models, which are single parameter distributions.</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_nec ~ gamma(2, 0.0533333333333333)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL 'b219b9b3bc2387c567eef001e65b92c9' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000181 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.81 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 11.0961 seconds (Warm-up)
#&gt; Chain 1:                2.43635 seconds (Sampling)
#&gt; Chain 1:                13.5325 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b219b9b3bc2387c567eef001e65b92c9' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 3.1e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 11.7839 seconds (Warm-up)
#&gt; Chain 2:                1.11766 seconds (Sampling)
#&gt; Chain 2:                12.9016 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b219b9b3bc2387c567eef001e65b92c9' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 2.8e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 12.4782 seconds (Warm-up)
#&gt; Chain 3:                2.64536 seconds (Sampling)
#&gt; Chain 3:                15.1236 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b219b9b3bc2387c567eef001e65b92c9' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 0.00017 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.7 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 11.2774 seconds (Warm-up)
#&gt; Chain 4:                2.56521 seconds (Sampling)
#&gt; Chain 4:                13.8426 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: Found 3 observations with a pareto_k &gt; 0.7 in model 'fit'. It is
#&gt; recommended to set 'moment_match = TRUE' in order to perform moment matching for
#&gt; problematic observations.
#&gt; Warning: 
#&gt; 23 (47.9%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec3param model using a binomial distribution.</code></pre>
<p>A test for over or under-dispersion is performed by <em>bayesnec</em>, and this can be extracted using <em>$dispersion</em>. Values &gt;1 indicate over-dispersion and values &lt;1 indicate under-dispersion. In this case the overdispersion value is much bigger than 1, indicating quite extreme overdispersion (meaning our model doesn’t properly capture the true variability represented in this data). Over and under-dispersion can be due to a poor fitting model, as well as violation of the distribution assumptions of the fitted data (for example, when the response data are poisson, the variance should equal to the mean, which is often not the case).</p>
<div class="sourceCode" id="cb19"><pre class="downlit">
<span class="kw">out</span><span class="op">$</span><span class="kw">dispersion</span>
<span class="co">#&gt; Estimate     Q2.5    Q97.5 </span>
<span class="co">#&gt; 21.70083 14.36546 34.40088</span>
</pre></div>
<p>First, let’s see if the model fits better using a log transformation of the x-data, given these appear to have been set on a log scaling anyway (based on the spacing between the treatment values).</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '1113ecee5d95d3d0743ff2f16b24181b' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000178 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.78 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 3.63843 seconds (Warm-up)
#&gt; Chain 1:                2.08469 seconds (Sampling)
#&gt; Chain 1:                5.72312 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '1113ecee5d95d3d0743ff2f16b24181b' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 8.8e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.88 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 3.88692 seconds (Warm-up)
#&gt; Chain 2:                1.9969 seconds (Sampling)
#&gt; Chain 2:                5.88382 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '1113ecee5d95d3d0743ff2f16b24181b' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 9.1e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.91 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 3.5705 seconds (Warm-up)
#&gt; Chain 3:                2.21075 seconds (Sampling)
#&gt; Chain 3:                5.78125 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '1113ecee5d95d3d0743ff2f16b24181b' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 3e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 4.8956 seconds (Warm-up)
#&gt; Chain 4:                0.760481 seconds (Sampling)
#&gt; Chain 4:                5.65608 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: Found 2 observations with a pareto_k &gt; 0.7 in model 'fit'. It is
#&gt; recommended to set 'moment_match = TRUE' in order to perform moment matching for
#&gt; problematic observations.
#&gt; Warning: 
#&gt; 22 (45.8%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec3param model using a binomial distribution.</code></pre>
<p>Using the log data the residual plot looks a little better, although there is a tendency to underestimate the response (the residual plot appears to be negatively biased). Note that we still have an over dispersion estimate of over 1.</p>
<p>By default <em>bayesnec</em> will fit a 3 parameter <em>NEC</em> model (<em>model = nec3param</em>) which has the parameters <em>top</em> (the mean value of the response without any effect of the toxicant), <em>nec</em> (the concentration at which an effect of the toxicant begins to occur), and <em>beta</em> (the rate of exponential decay of the response). However there are other models that have been implemented, including (but not limited to): <em>nec4param</em>, which is equivalent to <em>nec3param</em> but includes a <em>bot</em> parameter (the bottom plateau); and <em>ecx4param</em>, with parameters <em>top</em> (the upper plateau of the response), <em>ec50</em> (the <em>EC50</em> estimate of the curve), <em>beta</em> (the rate of exponential decay of the response), and <em>bot</em> (the bottom plateau). An <em>ECx</em> model can be used when evidence for an <em>NEC</em> model is weak (ie there is a consistent decline with increasing concentration and no evidence of a <em>step</em>). For <em>model = ecx4param</em>, no <em>nec</em> parameter can be formally derived, although an approximation based on the <em>NSEC</em> concept described under <em>background</em> is currently returned by default on all <em>ecx</em> model output. At this time the concept has not be formally tested or peer reviewed and should be used with caution.</p>
<p>Let’s now try fitting the same data using the 4-parameter <em>NEC</em> model.</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '7f97294a64500a8c82e70e85fbebf35e' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 7.5e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.75 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 12.1141 seconds (Warm-up)
#&gt; Chain 1:                2.93952 seconds (Sampling)
#&gt; Chain 1:                15.0536 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '7f97294a64500a8c82e70e85fbebf35e' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 0.000113 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.13 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 12.5316 seconds (Warm-up)
#&gt; Chain 2:                3.45124 seconds (Sampling)
#&gt; Chain 2:                15.9828 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '7f97294a64500a8c82e70e85fbebf35e' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 4.3e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.43 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 8.76546 seconds (Warm-up)
#&gt; Chain 3:                2.26444 seconds (Sampling)
#&gt; Chain 3:                11.0299 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '7f97294a64500a8c82e70e85fbebf35e' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 9e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.9 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 7.91852 seconds (Warm-up)
#&gt; Chain 4:                2.80924 seconds (Sampling)
#&gt; Chain 4:                10.7278 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 2559 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Warning: Found 7 observations with a pareto_k &gt; 0.7 in model 'fit'. It is
#&gt; recommended to set 'moment_match = TRUE' in order to perform moment matching for
#&gt; problematic observations.
#&gt; Warning: 
#&gt; 22 (45.8%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec4param model using a binomial distribution.
#&gt; Estimate     Q2.5    Q97.5 
#&gt; 21.26544 14.13382 33.43182</code></pre>
<p>Even for the 4-parameter <em>NEC</em> model we still have an overdispersion parameter over 1, suggesting that our 95% confidence band on the <em>NEC</em> will be far smaller than what it should be in reality. It does seem there is a more gradual decline in this data, so it is possible the 4-parameter <em>ECx</em> model will fit better. Let’s try fitting that now.</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '766d6326a35c00874cfa1eeffede6eea' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000195 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.95 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 7.75652 seconds (Warm-up)
#&gt; Chain 1:                2.07033 seconds (Sampling)
#&gt; Chain 1:                9.82685 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '766d6326a35c00874cfa1eeffede6eea' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 0.000105 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.05 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 6.66958 seconds (Warm-up)
#&gt; Chain 2:                0.848092 seconds (Sampling)
#&gt; Chain 2:                7.51767 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '766d6326a35c00874cfa1eeffede6eea' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 4e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.4 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 7.6957 seconds (Warm-up)
#&gt; Chain 3:                0.819989 seconds (Sampling)
#&gt; Chain 3:                8.51569 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '766d6326a35c00874cfa1eeffede6eea' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 4e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.4 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 13.2784 seconds (Warm-up)
#&gt; Chain 4:                1.00011 seconds (Sampling)
#&gt; Chain 4:                14.2785 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 34 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Warning: Found 4 observations with a pareto_k &gt; 0.7 in model 'fit'. It is
#&gt; recommended to set 'moment_match = TRUE' in order to perform moment matching for
#&gt; problematic observations.
#&gt; Warning: 
#&gt; 24 (50.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a ecx4param model using a binomial distribution.
#&gt; Estimate     Q2.5    Q97.5 
#&gt; 21.08147 14.13516 33.27415</code></pre>
<p>This model does look like it fits a little bit better than the either of the two <em>NEC</em> models. The residual plot shows a more even distribution of the data around the fitted line. However, the overdispersion estimate suggests this model is still over dispersed, meaning our confidence bounds are still too narrow.</p>
<p>If your model is overdispersed, depending on your type of reseponse data, it is possible to fit a different family to accomodate the overdispersion. For a Poisson, it may help to use a negative binomial distribution (thus allowing the variance and mean to be independent). For binomial response data, it is possible to model the proportions direction using a beta distribution. Note that in this case it is important that the number of trials making up the proportions is similar for all rows of data, because we loose the information that some of the proportions may be based on more or less data than others, which is accounted for in our binomial model.</p>
<p>For all model types a wide range of distributions are available for the response variable <em>y_var</em>. As detailed above, if <em>y_type</em> is unspecified <em>bayesnec</em> will attempt to guess the right distribution to use. This can of course be manually specified. Here we will apply a beta model to our binomial data. First we calculate our proportions and then we specify <em>family=“Beta(link=”identity)"</em>. Actually in this case we can just re-run the bnec call without specifying any family, but using y_var as the new <em>prop</em> column - the proportions, and it will automatically choose a beta.</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '5b375a96bf51c828b7083d9a880871d5' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.00023 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.3 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 14.4567 seconds (Warm-up)
#&gt; Chain 1:                4.8309 seconds (Sampling)
#&gt; Chain 1:                19.2876 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '5b375a96bf51c828b7083d9a880871d5' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 4.3e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.43 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 15.0476 seconds (Warm-up)
#&gt; Chain 2:                3.36108 seconds (Sampling)
#&gt; Chain 2:                18.4087 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '5b375a96bf51c828b7083d9a880871d5' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 0.000122 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.22 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 16.743 seconds (Warm-up)
#&gt; Chain 3:                4.40617 seconds (Sampling)
#&gt; Chain 3:                21.1492 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '5b375a96bf51c828b7083d9a880871d5' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 0.000117 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.17 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 15.1068 seconds (Warm-up)
#&gt; Chain 4:                1.72548 seconds (Sampling)
#&gt; Chain 4:                16.8322 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 7761 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Response variable modelled as a ecx4param model using a beta distribution.</code></pre>
<p>From the results we can see that we now have a much better fit in terms of dispersion, with an over-dispersion parameter of NA, NA, NA, and much wider more representative confidence bands. Let us see if the <em>beta</em> distribution would also have improved our original <em>NEC</em> model fit.</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '9b56133e6d0f3d1f74396511852582fa' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000206 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.06 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 11.7345 seconds (Warm-up)
#&gt; Chain 1:                4.19376 seconds (Sampling)
#&gt; Chain 1:                15.9283 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '9b56133e6d0f3d1f74396511852582fa' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 0.000103 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.03 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 11.8933 seconds (Warm-up)
#&gt; Chain 2:                4.26538 seconds (Sampling)
#&gt; Chain 2:                16.1587 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '9b56133e6d0f3d1f74396511852582fa' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 0.000104 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.04 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 12.3818 seconds (Warm-up)
#&gt; Chain 3:                4.30199 seconds (Sampling)
#&gt; Chain 3:                16.6838 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '9b56133e6d0f3d1f74396511852582fa' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 0.000105 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.05 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 13.685 seconds (Warm-up)
#&gt; Chain 4:                3.60124 seconds (Sampling)
#&gt; Chain 4:                17.2862 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: 
#&gt; 1 (2.1%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec3param model using a beta distribution.
#&gt; [1] NA NA NA</code></pre>
<p>Yes it seems that the beta distribution provides a good fit to these data regardless of which model is fit, and should probably be used for these data.</p>
</div>
<div id="fitting-multiple-models-and-model-averaging-using-the-bnec-function" class="section level2">
<h2 class="hasAnchor">
<a href="#fitting-multiple-models-and-model-averaging-using-the-bnec-function" class="anchor"></a>Fitting multiple models and model averaging using the <em>bnec</em> function</h2>
<div id="fitting-a-bnec-model" class="section level3">
<h3 class="hasAnchor">
<a href="#fitting-a-bnec-model" class="anchor"></a>Fitting a <em>bnec</em> model</h3>
<p>So far we have explored how to fit individual models via the function <em>bnec</em>. The <em>bayesnec</em> package also has the capacity to fit a custom selection of models, pre-specified sets of models or even all the available models in the package. Note that as these are Bayesian methods requiring multiple MCMC chains using <em>bnec</em> can be very slow. See details under <em>?bnec</em> for more information on the models, and model sets that can be specied.</p>
<pre><code>#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; recompiling to avoid crashing R session
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '9b56133e6d0f3d1f74396511852582fa' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000213 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.13 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 13.3614 seconds (Warm-up)
#&gt; Chain 1:                2.62795 seconds (Sampling)
#&gt; Chain 1:                15.9893 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '9b56133e6d0f3d1f74396511852582fa' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 0.000108 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.08 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 12.8619 seconds (Warm-up)
#&gt; Chain 2:                3.47385 seconds (Sampling)
#&gt; Chain 2:                16.3358 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '9b56133e6d0f3d1f74396511852582fa' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 4.1e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 12.635 seconds (Warm-up)
#&gt; Chain 3:                3.5635 seconds (Sampling)
#&gt; Chain 3:                16.1985 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '9b56133e6d0f3d1f74396511852582fa' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 3.6e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 11.8226 seconds (Warm-up)
#&gt; Chain 4:                2.61339 seconds (Sampling)
#&gt; Chain 4:                14.436 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: 
#&gt; 1 (2.1%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec3param model using a beta distribution.
#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL 'b4dc45c05f4f94adc85b4722e5a0c743' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000263 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.63 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 19.0661 seconds (Warm-up)
#&gt; Chain 1:                5.93193 seconds (Sampling)
#&gt; Chain 1:                24.998 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b4dc45c05f4f94adc85b4722e5a0c743' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 4.9e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.49 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 19.3125 seconds (Warm-up)
#&gt; Chain 2:                8.59531 seconds (Sampling)
#&gt; Chain 2:                27.9078 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b4dc45c05f4f94adc85b4722e5a0c743' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 0.000124 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.24 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 19.1106 seconds (Warm-up)
#&gt; Chain 3:                6.54204 seconds (Sampling)
#&gt; Chain 3:                25.6526 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'b4dc45c05f4f94adc85b4722e5a0c743' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 4.8e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 19.0473 seconds (Warm-up)
#&gt; Chain 4:                4.19762 seconds (Sampling)
#&gt; Chain 4:                23.2449 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 10122 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Warning: 
#&gt; 1 (2.1%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nec4param model using a beta distribution.
#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_slope ~ gamma(2, 16.9912554318134)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL 'aca49fda9cde48065cb27907067fd2a0' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000311 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 3.11 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 10.7747 seconds (Warm-up)
#&gt; Chain 1:                3.08449 seconds (Sampling)
#&gt; Chain 1:                13.8592 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'aca49fda9cde48065cb27907067fd2a0' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 4.8e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 10.6824 seconds (Warm-up)
#&gt; Chain 2:                5.03916 seconds (Sampling)
#&gt; Chain 2:                15.7216 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'aca49fda9cde48065cb27907067fd2a0' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 4.9e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.49 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 11.4375 seconds (Warm-up)
#&gt; Chain 3:                3.19453 seconds (Sampling)
#&gt; Chain 3:                14.632 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'aca49fda9cde48065cb27907067fd2a0' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 0.000123 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.23 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 10.129 seconds (Warm-up)
#&gt; Chain 4:                3.06398 seconds (Sampling)
#&gt; Chain 4:                13.193 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 1008 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Warning: 
#&gt; 1 (2.1%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a nechorme model using a beta distribution.
#&gt; necsigm should only be called when x values are &gt;= 0
#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_slope ~ gamma(2, 16.9912554318134)
#&gt; b_top ~ beta(5, 1)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL 'd29bf1ecfdce1975fc7f62a72d7d69de' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 6.9e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.69 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 3.13563 seconds (Warm-up)
#&gt; Chain 1:                1.69171 seconds (Sampling)
#&gt; Chain 1:                4.82734 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'd29bf1ecfdce1975fc7f62a72d7d69de' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 9.6e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.96 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 3.02518 seconds (Warm-up)
#&gt; Chain 2:                0.611339 seconds (Sampling)
#&gt; Chain 2:                3.63652 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'd29bf1ecfdce1975fc7f62a72d7d69de' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 3.5e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 2.98871 seconds (Warm-up)
#&gt; Chain 3:                0.530511 seconds (Sampling)
#&gt; Chain 3:                3.51922 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'd29bf1ecfdce1975fc7f62a72d7d69de' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 3.3e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.33 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 3.01363 seconds (Warm-up)
#&gt; Chain 4:                0.543438 seconds (Sampling)
#&gt; Chain 4:                3.55706 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 40 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Response variable modelled as a ecxlin model using a beta distribution.
#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL 'ce1e60c704f74f4bae909521407f7d73' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000207 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.07 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 3.6923 seconds (Warm-up)
#&gt; Chain 1:                1.24725 seconds (Sampling)
#&gt; Chain 1:                4.93955 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'ce1e60c704f74f4bae909521407f7d73' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 3.5e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 3.16828 seconds (Warm-up)
#&gt; Chain 2:                0.972505 seconds (Sampling)
#&gt; Chain 2:                4.14078 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'ce1e60c704f74f4bae909521407f7d73' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 0.000147 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.47 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 3.65335 seconds (Warm-up)
#&gt; Chain 3:                0.831329 seconds (Sampling)
#&gt; Chain 3:                4.48468 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'ce1e60c704f74f4bae909521407f7d73' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 5.6e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.56 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 3.3103 seconds (Warm-up)
#&gt; Chain 4:                1.45715 seconds (Sampling)
#&gt; Chain 4:                4.76745 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 120 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Response variable modelled as a ecxexp model using a beta distribution.
#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '5b375a96bf51c828b7083d9a880871d5' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 9.1e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.91 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 11.6785 seconds (Warm-up)
#&gt; Chain 1:                2.81973 seconds (Sampling)
#&gt; Chain 1:                14.4982 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '5b375a96bf51c828b7083d9a880871d5' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 4.6e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.46 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 12.0902 seconds (Warm-up)
#&gt; Chain 2:                5.54233 seconds (Sampling)
#&gt; Chain 2:                17.6326 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '5b375a96bf51c828b7083d9a880871d5' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 6.2e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.62 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 11.6426 seconds (Warm-up)
#&gt; Chain 3:                5.65669 seconds (Sampling)
#&gt; Chain 3:                17.2993 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '5b375a96bf51c828b7083d9a880871d5' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 6.7e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.67 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 11.6403 seconds (Warm-up)
#&gt; Chain 4:                3.54061 seconds (Sampling)
#&gt; Chain 4:                15.1809 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 7666 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Response variable modelled as a ecx4param model using a beta distribution.
#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL '724d4ccf93547d2ecbcf9678e857d707' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 0.000228 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.28 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 9.15751 seconds (Warm-up)
#&gt; Chain 1:                2.93648 seconds (Sampling)
#&gt; Chain 1:                12.094 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '724d4ccf93547d2ecbcf9678e857d707' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 6.7e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.67 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 8.76781 seconds (Warm-up)
#&gt; Chain 2:                2.57502 seconds (Sampling)
#&gt; Chain 2:                11.3428 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '724d4ccf93547d2ecbcf9678e857d707' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 7.2e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.72 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 9.51351 seconds (Warm-up)
#&gt; Chain 3:                2.16611 seconds (Sampling)
#&gt; Chain 3:                11.6796 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '724d4ccf93547d2ecbcf9678e857d707' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 4.6e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.46 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 8.79327 seconds (Warm-up)
#&gt; Chain 4:                2.64035 seconds (Sampling)
#&gt; Chain 4:                11.4336 seconds (Total)
#&gt; Chain 4:
#&gt; Warning: There were 1985 divergent transitions after warmup. See
#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#&gt; to find out why this is a problem and how to eliminate them.
#&gt; Warning: Examine the pairs() plot to diagnose sampling problems
#&gt; Warning: 
#&gt; 1 (2.1%) p_waic estimates greater than 0.4. We recommend trying loo instead.
#&gt; Response variable modelled as a ecxwb1 model using a beta distribution.
#&gt; Warning: It appears as if you have specified a lower bounded prior on a parameter that has no natural lower bound.
#&gt; If this is really what you want, please specify argument 'lb' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_beta ~ gamma(0.5, 2)
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.
#&gt; If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.
#&gt; Warning occurred for prior 
#&gt; b_top ~ beta(5, 1)
#&gt; b_bot ~ beta(1, 5)
#&gt; Compiling Stan program...
#&gt; Start sampling
#&gt; 
#&gt; SAMPLING FOR MODEL 'a8f6254dd1d3395c9c753b6c8cbd1d9d' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 8.6e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.86 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 1: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 6.19527 seconds (Warm-up)
#&gt; Chain 1:                2.34848 seconds (Sampling)
#&gt; Chain 1:                8.54375 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'a8f6254dd1d3395c9c753b6c8cbd1d9d' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 4.1e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 2: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 2: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 2: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 6.96158 seconds (Warm-up)
#&gt; Chain 2:                1.96256 seconds (Sampling)
#&gt; Chain 2:                8.92415 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'a8f6254dd1d3395c9c753b6c8cbd1d9d' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 4.4e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 3: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 3: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 3: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 7.01948 seconds (Warm-up)
#&gt; Chain 3:                1.60323 seconds (Sampling)
#&gt; Chain 3:                8.62271 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'a8f6254dd1d3395c9c753b6c8cbd1d9d' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 0.000117 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.17 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  4000 / 20000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  6000 / 20000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  8000 / 20000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 10000 / 20000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 12000 / 20000 [ 60%]  (Warmup)
#&gt; Chain 4: Iteration: 14000 / 20000 [ 70%]  (Warmup)
#&gt; Chain 4: Iteration: 16000 / 20000 [ 80%]  (Warmup)
#&gt; Chain 4: Iteration: 16001 / 20000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 42.691 seconds (Warm-up)
#&gt; Chain 4:                2.27005 seconds (Sampling)
#&gt; Chain 4:                44.961 seconds (Total)
#&gt; Chain 4:
#&gt; Response variable modelled as a ecxwb2 model using a beta distribution.
#&gt; successfully fitted the models:  nec3param nec4param nechorme ecxlin ecxexp ecx4param ecxwb1 ecxwb2</code></pre>
<p>Here we run <em>bnec</em> usin gmodel = <em>all</em> using the proportional data example for a beta response variable from above, and save the output as an <em>.RData</em> file so that the rmarkdown will not include all of the console output that is generated when these models run. Saving an <em>.RData</em> file of the <em>all</em> model <em>bnec</em> output can be a useful way of fitting all the models at a convenient time (this can be very slow, so you can run this overnight for example) and reloading them later to explore, plot, extract values, and amend the model set as required.</p>
</div>
<div id="exploring-a-bayesmanecfit-model" class="section level3">
<h3 class="hasAnchor">
<a href="#exploring-a-bayesmanecfit-model" class="anchor"></a>Exploring a <em>bayesmanecfit</em> model</h3>
<p>We have created some plotting method functions for our <em>bayesnec</em> model types, so we can plot a <em>bayesmanecfit</em> model object simply with <em>plot</em>.</p>
<div class="sourceCode" id="cb26"><pre class="downlit">
<span class="co">#plot(out)</span>
</pre></div>
<p>The default plot looks exactly the same out our regular <em>bayesnecfit</em> plot, but the output is based in a weighted average of all the models fits. The <em>NEC</em> estimate on this plot is based on a mix of actual <em>NEC</em> estimates, as well as the <em>NSEC</em> estimates that are used as an approximation to <em>NEC</em> for all the <em>ecx</em> models in the set. Note that we do not currently recommend reporting this values as the <em>NEC</em> (see below). The fitted <em>bayesmanecfit</em> object contains different elements to the <em>bayesnecfit</em>. In particular</p>
<div class="sourceCode" id="cb27"><pre class="downlit">
<span class="kw">out</span><span class="op">$</span><span class="kw">mod_stats</span>
<span class="co">#&gt;               model      waic           wi dispersion_Estimate dispersion_Q2.5</span>
<span class="co">#&gt; nec3param nec3param -69.45671 4.593497e-04                  NA              NA</span>
<span class="co">#&gt; nec4param nec4param -68.83955 1.268776e-05                  NA              NA</span>
<span class="co">#&gt; nechorme   nechorme -66.73423 5.405022e-06                  NA              NA</span>
<span class="co">#&gt; ecxlin       ecxlin -30.19570 8.883812e-10                  NA              NA</span>
<span class="co">#&gt; ecxexp       ecxexp -27.16171 1.428643e-09                  NA              NA</span>
<span class="co">#&gt; ecx4param ecx4param -71.68433 7.747957e-01                  NA              NA</span>
<span class="co">#&gt; ecxwb1       ecxwb1 -71.34253 2.247148e-01                  NA              NA</span>
<span class="co">#&gt; ecxwb2       ecxwb2 -69.12958 1.208173e-05                  NA              NA</span>
<span class="co">#&gt;           dispersion_Q97.5</span>
<span class="co">#&gt; nec3param               NA</span>
<span class="co">#&gt; nec4param               NA</span>
<span class="co">#&gt; nechorme                NA</span>
<span class="co">#&gt; ecxlin                  NA</span>
<span class="co">#&gt; ecxexp                  NA</span>
<span class="co">#&gt; ecx4param               NA</span>
<span class="co">#&gt; ecxwb1                  NA</span>
<span class="co">#&gt; ecxwb2                  NA</span>
</pre></div>
<p>contains the table of model fit statistic for all the fitted models. This includes the model name, the WAIC (as returned from <em>brms</em>), WAIC.delta (WAIC - the lowest WAIC), wi (the model weight), pD, and the overdispersion estimate. For this example, three models have relatively similar weights and contribute to the model averaged outcome, including the <em>nec3param</em>, <em>nec4param</em> and the <em>ecx4param</em> models, with the <em>nec4param</em> being overall the highest.</p>
<p>The <em>bayesmanecfit</em> object also contains all of the original fits, which can be extracted using the <em>pull_out</em> function.</p>
<div class="sourceCode" id="cb28"><pre class="downlit">
<span class="kw">out.nec3param</span> <span class="op">&lt;-</span><span class="fu"><a href="../reference/pull_out.html">pull_out</a></span>(<span class="kw">out</span>, model = <span class="st">"nec3param"</span>)
<span class="co">#&gt; Successfully pulled out model(s): nec3param</span>
<span class="co">#plot(out.nec3param)</span>
</pre></div>
<p>This would extract the <em>nec3param</em> model from the <em>bayesmanecfit</em> and create a new object that contains just this <em>bayesnecfit</em> fit. This would be identical to fitting the <em>nec3param</em> as a single model using <em>bnec</em> as we did above. All of the models in the <em>bayesmanecfit</em> can be simultaneously plotted using</p>
<div class="sourceCode" id="cb29"><pre class="downlit">
<span class="co">#plot(out, all_models = TRUE)</span>
</pre></div>
<p>The models prefixed with <em>ecx</em> are all models that do not have the <em>NEC</em> as a parameter in the model. That is they are smooth curves as a function of concentration and have no breakpoint. The <em>NEC</em> on the plot above for these models are an approximation based on <em>NSEC</em> (see above) and should not be used without careful consideration of the validity of this endpoint value. A formal model averaged estimate of <em>NEC</em> should be obtained with <em>model = “NEC”</em>, and there is a helper function <em>amend</em> that can be used to alter the model set as required. We can use this to obtain first a set of <em>NEC</em> only models</p>
<pre><code>#&gt; Model(s) necsigm non-existent in current set of models: nec3param, nec4param, nechorme, ecxlin, ecxexp, ecx4param, ecxwb1, ecxwb2.
#&gt; If needed, add desired model(s) via function amend (see ?amend)
#&gt; Successfully pulled out model(s): nec3param, nec4param, nechorme</code></pre>
<p>We can drop other models from the set if desired, for example let’s drop the nechormesis model using the <em>amend</em> function</p>
<div class="sourceCode" id="cb31"><pre class="downlit">

<span class="kw">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/amend.html">amend</a></span>(<span class="kw">out.NEC</span>, drop = <span class="st">"nechormesis"</span>)
<span class="co">#&gt; Nothing to amend, please specify a model to either add or drop that differs from the original set</span>
<span class="co">#&gt; Returning original model set</span>
</pre></div>
<p>Now we have two model sets, an <em>NEC</em> set and a mixed <em>NEC</em> and <em>ECx</em> set. Of course before we use this model set for any inference, we would need to check the chain mixing and acf plot for each of the input models. For the all set, the models this highest weight are ecx4param and ecxwb1. We can assess the chains for these models to make sure they are good.</p>
<div class="sourceCode" id="cb32"><pre class="downlit">
<span class="co">#plot(out$mod_fits$ecx4param$fit)</span>
<span class="co">#plot(out$mod_fits$ecxwb1$fit)</span>
</pre></div>
<p>Now we can use the ecx function to get EC10 and ec50 values. We can do this using our all model set, because it is valid to use <em>NEC</em> models for estimating <em>ECx</em>.</p>
<div class="sourceCode" id="cb33"><pre class="downlit">
<span class="kw">ECx10</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ecx.html">ecx</a></span>(<span class="kw">out</span>, ecx_val = <span class="fl">10</span>)
<span class="kw">ECx50</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ecx.html">ecx</a></span>(<span class="kw">out</span>, ecx_val = <span class="fl">50</span>)

<span class="kw">ECx10</span>
<span class="co">#&gt;    ec_10 ec_10_lw ec_10_up </span>
<span class="co">#&gt; 3.957388 3.542271 4.455529</span>
<span class="kw">ECx50</span>
<span class="co">#&gt;    ec_50 ec_50_lw ec_50_up </span>
<span class="co">#&gt; 4.712902 4.430622 5.028392</span>
</pre></div>
<p>The weighted <em>NEC</em> estimates can be extracted directly from the <em>NEC</em> model set object, as they are an explicit parameter in these models.</p>
<div class="sourceCode" id="cb34"><pre class="downlit">
<span class="kw">NECvals</span> <span class="op">&lt;-</span> <span class="kw">out.NEC</span><span class="op">$</span><span class="kw">w_nec</span>
<span class="kw">NECvals</span>
<span class="co">#&gt; Estimate     Q2.5    Q97.5 </span>
<span class="co">#&gt; 3.831350 3.357188 4.372542</span>
</pre></div>
<p>Now we can make a combined plot of our output, showing the model averaged “<em>NEC</em>” model and the “all averaged model”, along with the relevant thresholds.</p>
<div class="sourceCode" id="cb35"><pre class="downlit">
<span class="co"># plot(out, add_nec = FALSE)</span>
<span class="co"># </span>
<span class="co"># abline(v = ECx10, col = "orange", lty = c(1, 3, 3))</span>
<span class="co"># abline(v = ECx50, col = "blue", lty = c(1, 3, 3))</span>
<span class="co"># abline(v = NECvals, col = "darkgrey", lty = c(3, 1, 3))</span>
<span class="co"># preds &lt;- out.NEC$w_pred_vals$data</span>
<span class="co"># lines(preds$x, preds$Estimate, col = "darkgrey")</span>
<span class="co"># lines(preds$x, preds$Q2.5, col = "darkgrey", lty = 3)</span>
<span class="co"># lines(preds$x, preds$Q97.5, col = "darkgrey", lty = 3)</span>
<span class="co"># legend("bottomleft",</span>
<span class="co">#   legend = c("Complete averaged model", "EC10", "ec50", "NEC"),</span>
<span class="co">#   col = c("black", "orange", "blue", "darkgrey"), lty = 1, bty = "n"</span>
<span class="co"># )</span>
</pre></div>
</div>
</div>
</div>
<div id="license" class="section level1">
<h1 class="hasAnchor">
<a href="#license" class="anchor"></a>License</h1>
<p>The code is released under the Apache License 2.0</p>
<pre><code>Copyright 2020 Australian Institute of Marine Science

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at 

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-Burnham2002">
<p>Burnham, K P, and D R Anderson. 2002. <em>Model Selection and Multimodel Inference; A Practical Information-Theoretic Approach</em>. 2nd ed. New York: Springer.</p>
</div>
<div id="ref-Burkner2017">
<p>Bürkner, Paul Christian. 2017. “brms: An R package for Bayesian multilevel models using Stan.” <em>Journal of Statistical Software</em>. <a href="https://doi.org/10.18637/jss.v080.i01">https://doi.org/10.18637/jss.v080.i01</a>.</p>
</div>
<div id="ref-Burkner2018">
<p>———. 2018. “Advanced Bayesian multilevel modeling with the R package brms.” <em>R Journal</em>. <a href="https://doi.org/10.32614/rj-2018-017">https://doi.org/10.32614/rj-2018-017</a>.</p>
</div>
<div id="ref-Fisher2020">
<p>Fisher, Rebecca, Gerard Ricardo, and David Fox. 2020. “Bayesian concentration-response modelling using jagsNEC.” <a href="https://doi.org/10.5281/ZENODO.3966864">https://doi.org/10.5281/ZENODO.3966864</a>.</p>
</div>
<div id="ref-Fox2010">
<p>Fox, David R. 2010. “A Bayesian approach for determining the no effect concentration and hazardous concentration in ecotoxicology.” <em>Ecotoxicology and Environmental Safety</em> 73 (2): 123–31.</p>
</div>
<div id="ref-Ritz2016">
<p>Ritz, Christian, Florent Baty, Jens C Streibig, and Daniel Gerhard. 2016. “Dose-Response Analysis Using R.” <em>PLoS ONE</em> 10 (12): e0146021. <a href="https://doi.org/10.1371/journal.pone.0146021">https://doi.org/10.1371/journal.pone.0146021</a>.</p>
</div>
<div id="ref-Su2015">
<p>Su, Yu-Sung, and Masanao Yajima. 2015. “R2jags: Using R to Run ’JAGS’. R package version 0.5-6. http://CRAN.R-project.org/package=R2jags.”</p>
</div>
<div id="ref-Thorley2018">
<p>Thorley, Joe, and Carl Schwarz. 2018. “ssdtools: Species Sensitivity Distributions. R package version 0.0.3. https://CRAN.R-project.org/package=ssdtools.”</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Rebecca Fisher, Diego Barneche, Gerard Ricardo, David Fox.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.9000.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
